{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook para la prueba de Porvenir Pensiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Una de las principales ventajas de contar con datos estructurados en una serie temporal, es que nos permiten realizar analísis a través de herramientas estadísticas y econométricas como: evaluación de estacionariedad para las realizaciones de la muestra (¿la serie de tiempo -en adelante st, que describe el volumen de transacciones es determinística, estocástica, o un poco de ambos?), evaluación de correlación serial (¿la st para el volumen de transacciones tiene una tendencia predecible o cambia de dirección de manera abrupta entre cada periodo?), visualización de filtros para promedios móviles (¿podemos establecer estrategias respuesta a los movimientos de la st?), entre otras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.layers import Input, Embedding, Dense, Flatten, Dropout, concatenate, LSTM\n",
    "from keras.layers import BatchNormalization, SpatialDropout1D\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer la base de datos\n",
    "file = \"data_01.txt\"\n",
    "data=pd.read_csv(file,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisar el tipo de datos que contiene el dataset\n",
    "print(data.dtypes)\n",
    "#Revisar sí hay missing values\n",
    "print ('# de valores vacios:')\n",
    "print (data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir el tipo de datos de la variable fecha\n",
    "data['fecha']=pd.to_datetime(data['fecha'])\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisión a la cantidad de operaciones y de terminales\n",
    "cantidadOperaciones=len(data.oper.unique())\n",
    "print('Existen '+ str(cantidadOperaciones) + ' tipo de operaciones que maneja la entidad bancaria')\n",
    "cantidadTerminales=len(data.idTerminal.unique())\n",
    "print('Existen '+ str(cantidadTerminales) + ' terminales a cargo de la entidad bancaria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se elige las cinco operaciones con mayor frecuencia en los datos\n",
    "tab = pd.crosstab(index=data[\"oper\"],columns=\"frecuencia\")\n",
    "tab_orden=tab.sort_values('frecuencia',ascending=False)\n",
    "print(tab_orden[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se eligen cinco terminales al azar\n",
    "auxTerm=data.idTerminal.unique()\n",
    "terminalesAleat = random.choices(auxTerm,k=5)\n",
    "print(terminalesAleat)\n",
    "a=terminalesAleat[0]\n",
    "b=terminalesAleat[1]\n",
    "c=terminalesAleat[2]\n",
    "d=terminalesAleat[3]\n",
    "e=terminalesAleat[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear df \n",
    "terminal_a=dataf.query('idTerminal == @a and oper == 0',inplace=False)\n",
    "print(terminal_a)\n",
    "#Agrupar la frecuencia de las operaciones de manera diaria\n",
    "terminal_as = terminal_a.groupby([terminal_a['fecha'].dt.date])['oper'].count().reset_index(name='Frecuencia')\n",
    "print(terminal_as)\n",
    "#Visualizar la st para el ensamblaje i \n",
    "terminal_as.plot(grid=True,figsize=(15,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficar contra la tendencia\n",
    "terminal_as_ciclo, terminal_as_tend = sm.tsa.filters.hpfilter(terminal_as['Frecuencia'])\n",
    "terminal_as['Tendencia'] = terminal_as_tend\n",
    "terminal_as[['Frecuencia', 'Tendencia']].plot(figsize=(10, 8), fontsize=12)\n",
    "legend = plt.legend()\n",
    "legend.prop.set_size(14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones importantes\n",
    "* Se debe generar periodos de tiempo comparables entre cada categoría de operación. Por lo cual, se opta por transformar la variable \"fecha\" de 'horas exactas' -lo cual emula una realización continua de la st,  a un periodo regular como lo puede ser 'diaria' -para obtener observaciones discretas de la st.\n",
    "* Para trabajar el modelo de aprendizaje con variables categóricas, se requiere la incorporación de *embeddings* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Considerando la naturaleza de la variable 'oper' se opta por "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo de aprendizaje\n",
    "terminal_as['weekday']=[x.weekday() for x in terminal_as.index]\n",
    "terminal_as['month']=[x.month for x in terminal_as.index]\n",
    "print(terminal_as)\n",
    "\n",
    "PASOS=7\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    terminal_as = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(terminal_as.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(terminal_as.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "# load dataset\n",
    "values = terminal_as['Frecuencia'].values\n",
    "\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "values=values.reshape(-1, 1) # esto lo hacemos porque tenemos 1 sola dimension\n",
    "\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "reframed = series_to_supervised(scaled, PASOS, 1)\n",
    "reframed.reset_index(inplace=True, drop=True)\n",
    "\n",
    "contador=0\n",
    "reframed['weekday']=terminal_as['weekday']\n",
    "reframed['month']=terminal_as['month']\n",
    "\n",
    "for i in range(reframed.index[0],reframed.index[-1]):\n",
    "    reframed['weekday'].loc[contador]=terminal_as['weekday'][i+8]\n",
    "    reframed['month'].loc[contador]=terminal_as['month'][i+8]\n",
    "    contador=contador+1\n",
    "print(reframed.head())\n",
    "\n",
    "reordenado=reframed[ ['weekday','month','var1(t-7)','var1(t-6)','var1(t-5)','var1(t-4)','var1(t-3)','var1(t-2)','var1(t-1)','var1(t)'] ]\n",
    "reordenado.dropna(inplace=True)\n",
    "\n",
    "training_data = reordenado.drop('var1(t)',axis=1)#.values\n",
    "target_data=reordenado['var1(t)']\n",
    "#training_data.head()\n",
    "print(reordenado)\n",
    "numerito=len(reordenado)\n",
    "\n",
    "valid_data = training_data[numerito-30:numerito]\n",
    "valid_target=target_data[numerito-30:numerito]\n",
    "\n",
    "training_data = training_data[0:numerito-30]\n",
    "target_data=target_data[0:numerito-30]\n",
    "print(training_data.shape,target_data.shape,valid_data.shape,valid_target.shape)\n",
    "#training_data.head()\n",
    "\n",
    "def crear_modeloEmbeddings():\n",
    "    emb_dias = 2 #tamanio profundidad de embeddings\n",
    "    emb_meses = 4\n",
    "\n",
    "    in_dias = Input(shape=[1], name = 'dias')\n",
    "    emb_dias = Embedding(7+1, emb_dias)(in_dias)\n",
    "    in_meses = Input(shape=[1], name = 'meses')\n",
    "    emb_meses = Embedding(12+1, emb_meses)(in_meses)\n",
    "\n",
    "    in_cli = Input(shape=[PASOS], name = 'cli')\n",
    "\n",
    "    fe = concatenate([(emb_dias), (emb_meses)])\n",
    "\n",
    "    x = Flatten()(fe)\n",
    "    x = Dense(PASOS,activation='tanh')(x)\n",
    "    outp = Dense(1,activation='tanh')(x)\n",
    "    model = Model(inputs=[in_dias,in_meses,in_cli], outputs=outp)\n",
    "\n",
    "    model.compile(loss='mean_absolute_error', \n",
    "                  optimizer='adam',\n",
    "                  metrics=['MSE'])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "EPOCHS=80\n",
    "\n",
    "model = crear_modeloEmbeddings()\n",
    "\n",
    "continuas=training_data[['var1(t-7)','var1(t-6)','var1(t-5)','var1(t-4)','var1(t-3)','var1(t-2)','var1(t-1)']]\n",
    "valid_continuas=valid_data[['var1(t-7)','var1(t-6)','var1(t-5)','var1(t-4)','var1(t-3)','var1(t-2)','var1(t-1)']]\n",
    "\n",
    "history=model.fit([training_data['weekday'],training_data['month'],continuas], target_data, epochs=EPOCHS\n",
    "                 ,validation_data=([valid_data['weekday'],valid_data['month'],valid_continuas],valid_target))\n",
    "\n",
    "\n",
    "results=model.predict([valid_data['weekday'],valid_data['month'],valid_continuas])\n",
    "print( len(results) )\n",
    "plt.scatter(range(len(valid_target)),valid_target,c='g')\n",
    "plt.scatter(range(len(results)),results,c='r')\n",
    "plt.title('validate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ventana con resultados\n",
    "ventana=tk.Tk()\n",
    "ventana.title('Inicio - Selección Operación')\n",
    "ventana.geometry('500x400+400+300')\n",
    "ventana.configure(background='white')\n",
    "\n",
    "el=tk.Label(ventana,text='Nombre_',bg='green',fg='white')\n",
    "el.pack(padx=5,pady=5,ipadx=5,ipady=5,fill=tk.X)\n",
    "entrada1=tk.Entry(ventana)\n",
    "var=tk.StringVar(ventana)\n",
    "var.set('--Seleccione--')\n",
    "opciones=tab_orden.oper[:5]\n",
    "option=tk.OptionMenu(ventana,var,*opciones)\n",
    "option.config(width=20)\n",
    "option.pack(side='left',padx=30,pady=30)\n",
    "e1=tk.Label(ventana,text='Animal seleccionado: ')\n",
    "e1.pack(padx=5,pady=5,ipadx=5,ipady=5,fill=tk.X)\n",
    "color=tk.Label(ventana,bg='plum',textvariable=var,pady=5,padx=5,width=50)\n",
    "color.pack()\n",
    "\n",
    "#entrada1.pack(fill=tk.X,padx=5,pady=5,ipadx=5,ipady=5)\n",
    "\n",
    "image=tk.PhotoImage(file='descarga.gif')\n",
    "image=image.subsample(1,1)\n",
    "label=tk.Label(image=image)\n",
    "label.pack()\n",
    "\n",
    "ventana.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Referencias*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Montenegro, Alvaro *Análisis de Series de Tiempo*, Editorial Pontificia Universidad Javeriana"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
